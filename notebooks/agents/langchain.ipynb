{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LangChain Experimentation\n",
    "\n",
    "Experiment with LangChain Agents through Open Source models."
   ],
   "id": "f96fd75532a86adc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Notebook Setup",
   "id": "375caa5582b97781"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "75d58392caa0e555"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-18T13:11:32.881236Z",
     "start_time": "2025-04-18T13:11:30.430928Z"
    }
   },
   "source": [
    "# Import standard Libraries\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_huggingface import HuggingFacePipeline, HuggingFaceEndpoint\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# HuggingFace",
   "id": "2f07889b064482bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pipeline - Text Generation",
   "id": "7850e1ed9e4bb77"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### From Model ID",
   "id": "8dd8c47876a3dc94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T12:58:45.098868Z",
     "start_time": "2025-04-18T12:55:09.917256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the pipeline\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\n",
    "        \"max_new_tokens\": 100,\n",
    "        \"top_k\": 50,\n",
    "        \"temperature\": 0.1,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Inference\n",
    "llm.invoke(\"Hugging Face is\")"
   ],
   "id": "f28e7013ffcf1bc5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.44k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca1d7c7a0ed849f3a97d4f5ddd52a2ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de80c8e1c61b4f94ae1f5e701bfca51e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ac8ea25edc04ee881bbf167b6cb1cbb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8de91cbd1c504588811421fec195d271"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09763f8cd43f4c7d878e9d4794dd9554"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "38f1862066d041fb9351835cebe08c59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/16.5k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "467fcc7a78db49e29f3a69c1df5922fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "345a4f487dcb4f47b4a0b6fcedc34896"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60d99415a5e740269b7037c51e050d4b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b41741d85d754807a7003e1e26420ecb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24143dd56f2d40d7919db79dda0c28e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49e68794e3ae47db86ad634aed4afe6c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "/Users/simone.porreca/Projects/NexusLLM/.venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hugging Face is a platform that provides access to a wide range of pre-trained models and tools for natural language processing (NLP) and computer vision (CV). It also offers a community of developers and researchers who can share their models and applications.\\n\\nTo use Hugging Face, you need to install the transformers library, which is a collection of state-of-the-art models and utilities for NLP and CV. You can install it using pip:\\n\\n```\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Transformer Pipeline",
   "id": "d7732bb09d7b72d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T13:09:22.508610Z",
     "start_time": "2025-04-18T13:07:55.148286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define tokenizer\n",
    "model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Define llm\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "# Create llm pipeline\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=100, top_k=50, temperature=0.1)\n",
    "\n",
    "# Bundle it with from LangChain\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "#Inference\n",
    "llm.invoke(\"Hugging Face is\")"
   ],
   "id": "de40ffbd16230998",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10e4920c15eb448980fea33e693c98d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "/Users/simone.porreca/Projects/NexusLLM/.venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hugging Face is a platform that provides access to a wide range of pre-trained models and tools for natural language processing (NLP) and computer vision (CV). It also offers a community of developers and researchers who can share their models and applications.\\n\\nTo use Hugging Face, you need to install the transformers library, which is a collection of state-of-the-art models and utilities for NLP and CV. You can install it using pip:\\n\\n```\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Endpoint - Text Generation",
   "id": "fcf54361ec0daa24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the HuggingFace endpoint\n",
    "# NOTE: It requires previous authentication\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\", # Or endpoint_url=\"<endpoint_url>\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=100,\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "# Inference\n",
    "llm.invoke(\"Hugging Face is\")"
   ],
   "id": "929c34b12015d223",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Embeddings",
   "id": "b2afeded19376168"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T13:11:36.488012Z",
     "start_time": "2025-04-18T13:11:35.439404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Instance the embeddings model\n",
    "model_name = \"mixedbread-ai/mxbai-embed-large-v1\"\n",
    "model = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    ")\n",
    "\n",
    "# Inference\n",
    "texts = [\"Hello, world!\", \"How are you?\"]\n",
    "model.embed_documents(texts)"
   ],
   "id": "e5e0a0eaa65db0cf",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.12/site-packages/langchain_huggingface/embeddings/huggingface.py:52\u001B[39m, in \u001B[36mHuggingFaceEmbeddings.__init__\u001B[39m\u001B[34m(self, **kwargs)\u001B[39m\n\u001B[32m     51\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m     \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msentence_transformers\u001B[39;00m  \u001B[38;5;66;03m# type: ignore[import]\u001B[39;00m\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.12/site-packages/sentence_transformers/__init__.py:14\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msentence_transformers\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbackend\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     10\u001B[39m     export_dynamic_quantized_onnx_model,\n\u001B[32m     11\u001B[39m     export_optimized_onnx_model,\n\u001B[32m     12\u001B[39m     export_static_quantized_openvino_model,\n\u001B[32m     13\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msentence_transformers\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcross_encoder\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mCrossEncoder\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m CrossEncoder\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msentence_transformers\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdatasets\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ParallelSentencesDataset, SentencesDataset\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/__init__.py:3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m__future__\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m annotations\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mCrossEncoder\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m CrossEncoder\n\u001B[32m      5\u001B[39m __all__ = [\u001B[33m\"\u001B[39m\u001B[33mCrossEncoder\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:18\u001B[39m\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PushToHubMixin\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msentence_transformers\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mevaluation\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mSentenceEvaluator\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SentenceEvaluator\n\u001B[32m     19\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msentence_transformers\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mreaders\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m InputExample\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.12/site-packages/sentence_transformers/evaluation/__init__.py:9\u001B[39m\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mMSEEvaluatorFromDataFrame\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m MSEEvaluatorFromDataFrame\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mNanoBEIREvaluator\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m NanoBEIREvaluator\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mParaphraseMiningEvaluator\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ParaphraseMiningEvaluator\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.12/site-packages/sentence_transformers/evaluation/NanoBEIREvaluator.py:11\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtqdm\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m tqdm\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msentence_transformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SentenceTransformer\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msentence_transformers\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mevaluation\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mInformationRetrievalEvaluator\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m InformationRetrievalEvaluator\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:33\u001B[39m\n\u001B[32m     31\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdynamic_module_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m get_class_from_dynamic_module, get_relative_import_files\n\u001B[32m---> \u001B[39m\u001B[32m33\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msentence_transformers\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodel_card\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SentenceTransformerModelCardData, generate_model_card\n\u001B[32m     34\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msentence_transformers\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msimilarity_functions\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SimilarityFunction\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.12/site-packages/sentence_transformers/model_card.py:35\u001B[39m\n\u001B[32m     34\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_datasets_available():\n\u001B[32m---> \u001B[39m\u001B[32m35\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mdatasets\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Dataset, DatasetDict, IterableDataset, IterableDatasetDict, Value\n\u001B[32m     37\u001B[39m logger = logging.getLogger(\u001B[34m__name__\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.12/site-packages/datasets/__init__.py:17\u001B[39m\n\u001B[32m     15\u001B[39m __version__ = \u001B[33m\"\u001B[39m\u001B[33m3.4.0\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01marrow_dataset\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Dataset\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01marrow_reader\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ReadInstruction\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:73\u001B[39m\n\u001B[32m     72\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m config\n\u001B[32m---> \u001B[39m\u001B[32m73\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01marrow_reader\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ArrowReader\n\u001B[32m     74\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01marrow_writer\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ArrowWriter, OptimizedTypedSequence\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.12/site-packages/datasets/arrow_reader.py:30\u001B[39m\n\u001B[32m     28\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtqdm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcontrib\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mconcurrent\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m thread_map\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdownload\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdownload_config\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m DownloadConfig  \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n\u001B[32m     31\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mnaming\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _split_re, filenames_for_dataset_split\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.12/site-packages/datasets/download/__init__.py:9\u001B[39m\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdownload_config\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m DownloadConfig\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdownload_manager\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m DownloadManager, DownloadMode\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mstreaming_download_manager\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m StreamingDownloadManager\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.12/site-packages/datasets/download/download_manager.py:32\u001B[39m\n\u001B[32m     31\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m tqdm \u001B[38;5;28;01mas\u001B[39;00m hf_tqdm\n\u001B[32m---> \u001B[39m\u001B[32m32\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfile_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     33\u001B[39m     ArchiveIterable,\n\u001B[32m     34\u001B[39m     FilesIterable,\n\u001B[32m     35\u001B[39m     cached_path,\n\u001B[32m     36\u001B[39m     is_relative_path,\n\u001B[32m     37\u001B[39m     stack_multiprocessing_download_progress_bars,\n\u001B[32m     38\u001B[39m     url_or_path_join,\n\u001B[32m     39\u001B[39m )\n\u001B[32m     40\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01minfo_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m get_size_checksum_dict\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.12/site-packages/datasets/utils/file_utils.py:46\u001B[39m\n\u001B[32m     45\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_filelock\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FileLock\n\u001B[32m---> \u001B[39m\u001B[32m46\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mextract\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ExtractManager\n\u001B[32m     47\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtrack\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m TrackedIterableFromGenerator\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.12/site-packages/datasets/utils/extract.py:3\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mgzip\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlzma\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mos\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/3.12.7/lib/python3.12/lzma.py:27\u001B[39m\n\u001B[32m     26\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mos\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m_lzma\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *\n\u001B[32m     28\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m_lzma\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _encode_filter_properties, _decode_filter_properties\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named '_lzma'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Instance the embeddings model\u001B[39;00m\n\u001B[32m      2\u001B[39m model_name = \u001B[33m\"\u001B[39m\u001B[33mmixedbread-ai/mxbai-embed-large-v1\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m model = \u001B[43mHuggingFaceEmbeddings\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[38;5;66;03m# Inference\u001B[39;00m\n\u001B[32m      8\u001B[39m texts = [\u001B[33m\"\u001B[39m\u001B[33mHello, world!\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mHow are you?\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.12/site-packages/langchain_huggingface/embeddings/huggingface.py:54\u001B[39m, in \u001B[36mHuggingFaceEmbeddings.__init__\u001B[39m\u001B[34m(self, **kwargs)\u001B[39m\n\u001B[32m     52\u001B[39m     \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msentence_transformers\u001B[39;00m  \u001B[38;5;66;03m# type: ignore[import]\u001B[39;00m\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m---> \u001B[39m\u001B[32m54\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[32m     55\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mCould not import sentence_transformers python package. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     56\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mPlease install it with `pip install sentence-transformers`.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     57\u001B[39m     ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mexc\u001B[39;00m\n\u001B[32m     59\u001B[39m \u001B[38;5;28mself\u001B[39m._client = sentence_transformers.SentenceTransformer(\n\u001B[32m     60\u001B[39m     \u001B[38;5;28mself\u001B[39m.model_name, cache_folder=\u001B[38;5;28mself\u001B[39m.cache_folder, **\u001B[38;5;28mself\u001B[39m.model_kwargs\n\u001B[32m     61\u001B[39m )\n",
      "\u001B[31mImportError\u001B[39m: Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`."
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a2457038527389ed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nexusllm",
   "language": "python",
   "name": "nexusllm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Embeddings - Fine Tuning Models\n",
    "\n",
    "The goal is to research different techniques on how to fine-tune embedding models.\n",
    "\n",
    "**Resources**\n",
    "- [Sentence Transformer - Loss Functions](https://sbert.net/docs/sentence_transformer/loss_overview.html#custom-loss-functions)"
   ],
   "id": "c616ee408a76b58d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Notebook Setup",
   "id": "caca82b7528d4b8e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "2e36bec4d703d96e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T18:56:03.718818Z",
     "start_time": "2025-04-27T18:56:03.716355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import Standard Libraries\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    "    SentenceTransformerModelCardData,\n",
    ")\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.evaluation import TripletEvaluator"
   ],
   "id": "d458ead545074057",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Read Data",
   "id": "caad35376609fdd5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## All NLI - Pair Class",
   "id": "139a2340c7d303a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T18:46:23.432644Z",
     "start_time": "2025-04-26T18:46:17.997556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read data the All NLI \"Pair Class\" datasets for SentenceTransformerTrainer\n",
    "all_nli_pair_class_train = load_dataset(\"sentence-transformers/all-nli\", \"pair-class\", split=\"train\")\n",
    "all_nli_pair_class_test = load_dataset(\"sentence-transformers/all-nli\", \"pair-class\", split=\"dev\")"
   ],
   "id": "50c4d76af1b7f514",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T10:13:34.343093Z",
     "start_time": "2025-04-25T10:13:34.337366Z"
    }
   },
   "cell_type": "code",
   "source": "all_nli_pair_class_train[5]",
   "id": "561ceb0ce3c5ddd9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'Children smiling and waving at camera',\n",
       " 'hypothesis': 'The kids are frowning',\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The `label` is `{\"0\": \"entailment\", \"1\": \"neutral\", \"2\", \"contradiction\"}`.",
   "id": "758903e4336acf63"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## All NLI - Triplets",
   "id": "4f83286d390a6eea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T19:02:41.296736Z",
     "start_time": "2025-04-27T19:02:29.827071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read data the All NLI \"Triplets\" datasets for SentenceTransformerTrainer\n",
    "all_nli_triplets_dataset = load_dataset(\"sentence-transformers/all-nli\", \"triplet\")\n",
    "all_nli_triplets_train = all_nli_triplets_dataset[\"train\"].select(range(100_000))\n",
    "all_nli_triplets_eval = all_nli_triplets_dataset[\"dev\"]\n",
    "all_nli_triplets_test = all_nli_triplets_dataset[\"test\"]"
   ],
   "id": "84c042bf6faa8c42",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "triplet/train-00000-of-00001.parquet:   0%|          | 0.00/38.4M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "07140cc03dda437385896c00671b0a31"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "triplet/dev-00000-of-00001.parquet:   0%|          | 0.00/782k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "157a90117d5141d2b204bace2dd83b9c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "triplet/test-00000-of-00001.parquet:   0%|          | 0.00/810k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc07ccdc5dcb460e9c72303d863f2d37"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/557850 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a74ec1d6117e4ba8b4e8c635f47895fe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating dev split:   0%|          | 0/6584 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a412c9481fc41af9cbd0aaf31190ecc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating test split:   0%|          | 0/6609 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6dc0af54cc5f4bbfb1c7fd60e86482b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T19:02:53.520271Z",
     "start_time": "2025-04-27T19:02:53.514644Z"
    }
   },
   "cell_type": "code",
   "source": "all_nli_triplets_train[5]",
   "id": "3a6ec44616693c2a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anchor': 'An older man is drinking orange juice at a restaurant.',\n",
       " 'positive': 'A man is drinking juice.',\n",
       " 'negative': 'Two women are at a restaurant drinking wine.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Preparation\n",
    "\n",
    "It is important to prepare the dataset in order to repsect a certain format expected by the Loss Function.\n",
    "\n",
    "- **Sentence Transformer** - The Loss Function expected format is reported in the [Loss Table](https://sbert.net/docs/sentence_transformer/loss_overview.html) and *label* column is generally indicated as `label` or `score`"
   ],
   "id": "5d583d769069fcfb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dataset - from_dict\n",
    "\n",
    "In case your data needs to be prepared, you can use the `Dataset.from_dict` and construct the list of values to insert into your dataset."
   ],
   "id": "ec9f4a81fda0da48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T12:11:25.224470Z",
     "start_time": "2025-04-25T12:11:25.214498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialise the data\n",
    "anchors = []\n",
    "positives = []\n",
    "\n",
    "# Open a file, perform preprocessing, filtering, cleaning, etc.\n",
    "# and append to the lists\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"anchor\": anchors,\n",
    "    \"positive\": positives,\n",
    "})"
   ],
   "id": "508840c42702c719",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# SentenceTransformerTrainer\n",
    "\n",
    "This library uses `datasets.Dataset ` ([Reference](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset)) or `datasets.DatasetDict` ([Reference](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.DatasetDict)) instances for both training and evaluation.\n",
    "\n",
    "They accept CSV, JSON, Parquet, Arrow or SQL.\n",
    "\n",
    "Such datasets are marked with `setnence-transformers` in the HuggingFace Datasets Hub."
   ],
   "id": "1712b9df63c323d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loss Functions - Cosine Sentence Similarity",
   "id": "29219b6158706107"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T12:42:41.841380Z",
     "start_time": "2025-04-25T12:42:33.175610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Instance model\n",
    "model = SentenceTransformer(\"microsoft/mpnet-base\")\n",
    "\n",
    "# Fine-tuning dataset with 2 samples\n",
    "# Data point: {text_1, text_2, expected_similarity}\n",
    "dataset = Dataset.from_dict({\n",
    "    \"sentence1\": [\"It's nice weather outside today.\", \"He drove to work.\"],\n",
    "    \"sentence2\": [\"It's so sunny.\", \"She walked to the store.\"],\n",
    "    \"score\": [1.0, 0.3]\n",
    "})\n",
    "\n",
    "# Cosine Sentence Loss -> Text 1, Text 2, Expected Similarity\n",
    "loss_function = CoSENTLoss(model)\n",
    "\n",
    "# Fine-tune\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    loss=loss_function\n",
    ")\n",
    "trainer.train()"
   ],
   "id": "6e2f9a630597a9b6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name microsoft/mpnet-base. Creating a new one with mean pooling.\n",
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b230d4986b44bc5b519c62fdefe909d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=0.3688153823216756, metrics={'train_runtime': 6.7357, 'train_samples_per_second': 0.891, 'train_steps_per_second': 0.445, 'total_flos': 0.0, 'train_loss': 0.3688153823216756, 'epoch': 3.0})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fine-Tune",
   "id": "3fc6b50657b06989"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load base Model",
   "id": "53dad4b877ea5c16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T19:04:29.258813Z",
     "start_time": "2025-04-27T19:04:27.499558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the model to fine-tune\n",
    "model = SentenceTransformer(\n",
    "    \"microsoft/mpnet-base\",\n",
    "    model_card_data=SentenceTransformerModelCardData(\n",
    "        language=\"en\",\n",
    "        license=\"apache-2.0\",\n",
    "        model_name=\"MPNet base trained on AllNLI triplets\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Define the loss function\n",
    "loss = MultipleNegativesRankingLoss(model)"
   ],
   "id": "5c220fbee1d9c73b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name microsoft/mpnet-base. Creating a new one with mean pooling.\n",
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Fine-Tuning Arguments",
   "id": "4a2de43465417cb2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T19:25:52.750199Z",
     "start_time": "2025-04-27T19:25:52.745408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the training arguments\n",
    "train_args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=\"models/mpnet-base-all-nli-triplet\",\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=False,  # GPU's specific\n",
    "    bf16=True,  # GPU's specific\n",
    "    # Optional tracking/debugging parameters:\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    "    run_name=\"all-nli-triplet\"\n",
    ")"
   ],
   "id": "b52b129ef6a892d5",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Base Model Evaluation\n",
    "\n",
    "The package `sentence_transformers.evaluation` offers several evaluation strategies for each specific use case. For example pair-class or triplets."
   ],
   "id": "49f1aec16b247007"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T19:09:44.840654Z",
     "start_time": "2025-04-27T19:08:57.090722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Base model evaluator\n",
    "base_evaluator = TripletEvaluator(\n",
    "    anchors=all_nli_triplets_eval[\"anchor\"],\n",
    "    positives=all_nli_triplets_eval[\"positive\"],\n",
    "    negatives=all_nli_triplets_eval[\"negative\"],\n",
    "    name=\"all-nli-dev\",\n",
    ")\n",
    "base_evaluator(model)"
   ],
   "id": "1291dfbf0310292f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all-nli-dev_cosine_accuracy': 0.621051013469696}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training",
   "id": "4d4b554a12d0fc80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T19:27:52.407781Z",
     "start_time": "2025-04-27T19:25:59.867656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the trainer and start training\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=all_nli_triplets_train,\n",
    "    eval_dataset=all_nli_triplets_eval,\n",
    "    loss=loss,\n",
    "    evaluator=base_evaluator,\n",
    ")\n",
    "trainer.train()"
   ],
   "id": "2ea071c7d22a3ebd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2365267795214cbd8b7ba837e3e78626"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='101' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 101/6250 00:54 < 56:26, 1.82 it/s, Epoch 0.02/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='412' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/412 00:54 < 00:16, 5.81 it/s]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Define the trainer and start training\u001B[39;00m\n\u001B[32m      2\u001B[39m trainer = SentenceTransformerTrainer(\n\u001B[32m      3\u001B[39m     model=model,\n\u001B[32m      4\u001B[39m     args=train_args,\n\u001B[32m   (...)\u001B[39m\u001B[32m      8\u001B[39m     evaluator=base_evaluator,\n\u001B[32m      9\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/transformers/trainer.py:2245\u001B[39m, in \u001B[36mTrainer.train\u001B[39m\u001B[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[39m\n\u001B[32m   2243\u001B[39m         hf_hub_utils.enable_progress_bars()\n\u001B[32m   2244\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2245\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2246\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2247\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2248\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2249\u001B[39m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2250\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/transformers/trainer.py:2627\u001B[39m, in \u001B[36mTrainer._inner_training_loop\u001B[39m\u001B[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[39m\n\u001B[32m   2625\u001B[39m     \u001B[38;5;28mself\u001B[39m.state.epoch = epoch + (step + \u001B[32m1\u001B[39m + steps_skipped) / steps_in_epoch\n\u001B[32m   2626\u001B[39m     \u001B[38;5;28mself\u001B[39m.control = \u001B[38;5;28mself\u001B[39m.callback_handler.on_step_end(args, \u001B[38;5;28mself\u001B[39m.state, \u001B[38;5;28mself\u001B[39m.control)\n\u001B[32m-> \u001B[39m\u001B[32m2627\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_maybe_log_save_evaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2628\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtr_loss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2629\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgrad_norm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2630\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2631\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2632\u001B[39m \u001B[43m        \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2633\u001B[39m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2634\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstart_time\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2635\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2636\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2637\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   2638\u001B[39m     \u001B[38;5;28mself\u001B[39m.control = \u001B[38;5;28mself\u001B[39m.callback_handler.on_substep_end(args, \u001B[38;5;28mself\u001B[39m.state, \u001B[38;5;28mself\u001B[39m.control)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/transformers/trainer.py:3096\u001B[39m, in \u001B[36mTrainer._maybe_log_save_evaluate\u001B[39m\u001B[34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001B[39m\n\u001B[32m   3094\u001B[39m metrics = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   3095\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.control.should_evaluate:\n\u001B[32m-> \u001B[39m\u001B[32m3096\u001B[39m     metrics = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3097\u001B[39m     is_new_best_metric = \u001B[38;5;28mself\u001B[39m._determine_best_metric(metrics=metrics, trial=trial)\n\u001B[32m   3099\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.save_strategy == SaveStrategy.BEST:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/transformers/trainer.py:3045\u001B[39m, in \u001B[36mTrainer._evaluate\u001B[39m\u001B[34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001B[39m\n\u001B[32m   3044\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_evaluate\u001B[39m(\u001B[38;5;28mself\u001B[39m, trial, ignore_keys_for_eval, skip_scheduler=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m-> \u001B[39m\u001B[32m3045\u001B[39m     metrics = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3046\u001B[39m     \u001B[38;5;28mself\u001B[39m._report_to_hp_search(trial, \u001B[38;5;28mself\u001B[39m.state.global_step, metrics)\n\u001B[32m   3048\u001B[39m     \u001B[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/sentence_transformers/trainer.py:462\u001B[39m, in \u001B[36mSentenceTransformerTrainer.evaluate\u001B[39m\u001B[34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001B[39m\n\u001B[32m    460\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    461\u001B[39m     eval_dataset = \u001B[38;5;28mself\u001B[39m.eval_dataset\n\u001B[32m--> \u001B[39m\u001B[32m462\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43meval_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/transformers/trainer.py:4154\u001B[39m, in \u001B[36mTrainer.evaluate\u001B[39m\u001B[34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001B[39m\n\u001B[32m   4151\u001B[39m start_time = time.time()\n\u001B[32m   4153\u001B[39m eval_loop = \u001B[38;5;28mself\u001B[39m.prediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.use_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.evaluation_loop\n\u001B[32m-> \u001B[39m\u001B[32m4154\u001B[39m output = \u001B[43meval_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4155\u001B[39m \u001B[43m    \u001B[49m\u001B[43meval_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4156\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mEvaluation\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   4157\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001B[39;49;00m\n\u001B[32m   4158\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# self.args.prediction_loss_only\u001B[39;49;00m\n\u001B[32m   4159\u001B[39m \u001B[43m    \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   4160\u001B[39m \u001B[43m    \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4161\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4162\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4164\u001B[39m total_batch_size = \u001B[38;5;28mself\u001B[39m.args.eval_batch_size * \u001B[38;5;28mself\u001B[39m.args.world_size\n\u001B[32m   4165\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_key_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_jit_compilation_time\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output.metrics:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/sentence_transformers/trainer.py:472\u001B[39m, in \u001B[36mSentenceTransformerTrainer.evaluation_loop\u001B[39m\u001B[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[39m\n\u001B[32m    464\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mevaluation_loop\u001B[39m(\n\u001B[32m    465\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    466\u001B[39m     dataloader: DataLoader,\n\u001B[32m   (...)\u001B[39m\u001B[32m    470\u001B[39m     metric_key_prefix: \u001B[38;5;28mstr\u001B[39m = \u001B[33m\"\u001B[39m\u001B[33meval\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    471\u001B[39m ) -> EvalLoopOutput:\n\u001B[32m--> \u001B[39m\u001B[32m472\u001B[39m     output = \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mevaluation_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    473\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    474\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    475\u001B[39m \u001B[43m        \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    476\u001B[39m \u001B[43m        \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    477\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    478\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    480\u001B[39m     \u001B[38;5;66;03m# If the evaluator is not defined, we can just return the output\u001B[39;00m\n\u001B[32m    481\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.evaluator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/transformers/trainer.py:4348\u001B[39m, in \u001B[36mTrainer.evaluation_loop\u001B[39m\u001B[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[39m\n\u001B[32m   4345\u001B[39m         batch_size = observed_batch_size\n\u001B[32m   4347\u001B[39m \u001B[38;5;66;03m# Prediction step\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m4348\u001B[39m losses, logits, labels = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mprediction_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4349\u001B[39m main_input_name = \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m.model, \u001B[33m\"\u001B[39m\u001B[33mmain_input_name\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33minput_ids\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   4350\u001B[39m inputs_decode = (\n\u001B[32m   4351\u001B[39m     \u001B[38;5;28mself\u001B[39m._prepare_input(inputs[main_input_name]) \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33minputs\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m args.include_for_metrics \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   4352\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/transformers/trainer.py:4564\u001B[39m, in \u001B[36mTrainer.prediction_step\u001B[39m\u001B[34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001B[39m\n\u001B[32m   4562\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_labels \u001B[38;5;129;01mor\u001B[39;00m loss_without_labels:\n\u001B[32m   4563\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m.compute_loss_context_manager():\n\u001B[32m-> \u001B[39m\u001B[32m4564\u001B[39m         loss, outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_outputs\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m   4565\u001B[39m     loss = loss.detach().mean()\n\u001B[32m   4567\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(outputs, \u001B[38;5;28mdict\u001B[39m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/sentence_transformers/trainer.py:406\u001B[39m, in \u001B[36mSentenceTransformerTrainer.compute_loss\u001B[39m\u001B[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001B[39m\n\u001B[32m    400\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    401\u001B[39m     model == \u001B[38;5;28mself\u001B[39m.model_wrapped\n\u001B[32m    402\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(loss_fn, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m)  \u001B[38;5;66;03m# Only if the loss stores the model\u001B[39;00m\n\u001B[32m    403\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m loss_fn.model != model  \u001B[38;5;66;03m# Only if the wrapped model is not already stored\u001B[39;00m\n\u001B[32m    404\u001B[39m ):\n\u001B[32m    405\u001B[39m     loss_fn = \u001B[38;5;28mself\u001B[39m.override_model_in_loss(loss_fn, model)\n\u001B[32m--> \u001B[39m\u001B[32m406\u001B[39m loss = \u001B[43mloss_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    407\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m return_outputs:\n\u001B[32m    408\u001B[39m     \u001B[38;5;66;03m# During prediction/evaluation, `compute_loss` will be called with `return_outputs=True`.\u001B[39;00m\n\u001B[32m    409\u001B[39m     \u001B[38;5;66;03m# However, Sentence Transformer losses do not return outputs, so we return an empty dictionary.\u001B[39;00m\n\u001B[32m    410\u001B[39m     \u001B[38;5;66;03m# This does not result in any problems, as the SentenceTransformerTrainingArguments sets\u001B[39;00m\n\u001B[32m    411\u001B[39m     \u001B[38;5;66;03m# `prediction_loss_only=True` which means that the output is not used.\u001B[39;00m\n\u001B[32m    412\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m loss, {}\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py:102\u001B[39m, in \u001B[36mMultipleNegativesRankingLoss.forward\u001B[39m\u001B[34m(self, sentence_features, labels)\u001B[39m\n\u001B[32m    100\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, sentence_features: Iterable[\u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Tensor]], labels: Tensor) -> Tensor:\n\u001B[32m    101\u001B[39m     \u001B[38;5;66;03m# Compute the embeddings and distribute them to anchor and candidates (positive and optionally negatives)\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m102\u001B[39m     embeddings = [\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43msentence_feature\u001B[49m\u001B[43m)\u001B[49m[\u001B[33m\"\u001B[39m\u001B[33msentence_embedding\u001B[39m\u001B[33m\"\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m sentence_feature \u001B[38;5;129;01min\u001B[39;00m sentence_features]\n\u001B[32m    103\u001B[39m     anchors = embeddings[\u001B[32m0\u001B[39m]  \u001B[38;5;66;03m# (batch_size, embedding_dim)\u001B[39;00m\n\u001B[32m    104\u001B[39m     candidates = torch.cat(embeddings[\u001B[32m1\u001B[39m:])  \u001B[38;5;66;03m# (batch_size * (1 + num_negatives), embedding_dim)\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/sentence_transformers/SentenceTransformer.py:753\u001B[39m, in \u001B[36mSentenceTransformer.forward\u001B[39m\u001B[34m(self, input, **kwargs)\u001B[39m\n\u001B[32m    751\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Tensor], **kwargs) -> \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Tensor]:\n\u001B[32m    752\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.module_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m753\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    755\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module_name, module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.named_children():\n\u001B[32m    756\u001B[39m         module_kwarg_keys = \u001B[38;5;28mself\u001B[39m.module_kwargs.get(module_name, [])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/torch/nn/modules/container.py:250\u001B[39m, in \u001B[36mSequential.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    248\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[32m    249\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m250\u001B[39m         \u001B[38;5;28minput\u001B[39m = \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    251\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/sentence_transformers/models/Transformer.py:442\u001B[39m, in \u001B[36mTransformer.forward\u001B[39m\u001B[34m(self, features, **kwargs)\u001B[39m\n\u001B[32m    435\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001B[39;00m\n\u001B[32m    436\u001B[39m trans_features = {\n\u001B[32m    437\u001B[39m     key: value\n\u001B[32m    438\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m features.items()\n\u001B[32m    439\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m [\u001B[33m\"\u001B[39m\u001B[33minput_ids\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mattention_mask\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mtoken_type_ids\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33minputs_embeds\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m    440\u001B[39m }\n\u001B[32m--> \u001B[39m\u001B[32m442\u001B[39m outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mauto_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mtrans_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    443\u001B[39m token_embeddings = outputs[\u001B[32m0\u001B[39m]\n\u001B[32m    444\u001B[39m features[\u001B[33m\"\u001B[39m\u001B[33mtoken_embeddings\u001B[39m\u001B[33m\"\u001B[39m] = token_embeddings\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/transformers/models/mpnet/modeling_mpnet.py:542\u001B[39m, in \u001B[36mMPNetModel.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001B[39m\n\u001B[32m    540\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    541\u001B[39m     attention_mask = torch.ones(input_shape, device=device)\n\u001B[32m--> \u001B[39m\u001B[32m542\u001B[39m extended_attention_mask: torch.Tensor = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_extended_attention_mask\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_shape\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    544\u001B[39m head_mask = \u001B[38;5;28mself\u001B[39m.get_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m.config.num_hidden_layers)\n\u001B[32m    545\u001B[39m embedding_output = \u001B[38;5;28mself\u001B[39m.embeddings(input_ids=input_ids, position_ids=position_ids, inputs_embeds=inputs_embeds)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:1602\u001B[39m, in \u001B[36mModuleUtilsMixin.get_extended_attention_mask\u001B[39m\u001B[34m(self, attention_mask, input_shape, device, dtype)\u001B[39m\n\u001B[32m   1593\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1594\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mWrong shape for input_ids (shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minput_shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m) or attention_mask (shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattention_mask.shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m)\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1595\u001B[39m     )\n\u001B[32m   1597\u001B[39m \u001B[38;5;66;03m# Since attention_mask is 1.0 for positions we want to attend and 0.0 for\u001B[39;00m\n\u001B[32m   1598\u001B[39m \u001B[38;5;66;03m# masked positions, this operation will create a tensor which is 0.0 for\u001B[39;00m\n\u001B[32m   1599\u001B[39m \u001B[38;5;66;03m# positions we want to attend and the dtype's smallest value for masked positions.\u001B[39;00m\n\u001B[32m   1600\u001B[39m \u001B[38;5;66;03m# Since we are adding it to the raw scores before the softmax, this is\u001B[39;00m\n\u001B[32m   1601\u001B[39m \u001B[38;5;66;03m# effectively the same as removing these entirely.\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1602\u001B[39m extended_attention_mask = \u001B[43mextended_attention_mask\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# fp16 compatibility\u001B[39;00m\n\u001B[32m   1603\u001B[39m extended_attention_mask = (\u001B[32m1.0\u001B[39m - extended_attention_mask) * torch.finfo(dtype).min\n\u001B[32m   1604\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m extended_attention_mask\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b5db0e63f6dd973d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

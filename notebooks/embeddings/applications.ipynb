{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Embeddings Applications\n",
    "\n",
    "Explore possible applications of embeddings."
   ],
   "id": "a282a4cfad0634bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup Notebook",
   "id": "2665f610ad299c49"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "25b4d58c5ac8b90f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T14:04:24.896647Z",
     "start_time": "2025-04-21T14:04:24.893912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import Standard Libraries\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers.util import semantic_search"
   ],
   "id": "c52cf38d992f1bb8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data",
   "id": "902896f2cef4d69d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T14:04:24.911388Z",
     "start_time": "2025-04-21T14:04:24.909185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# List of sentences\n",
    "sentences = [\n",
    "    \"Python is a great programming language for Machine Learning projects.\",\n",
    "    \"Java is a programming language mainly used for backend applications.\",\n",
    "    \"HTML and CSS are used to develop web applications.\",\n",
    "]"
   ],
   "id": "81c82961b7e7af88",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Semantic Search",
   "id": "9ba5e2d693f3018f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Sentence Transformers",
   "id": "a81b787df00b1ab9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T14:04:25.234391Z",
     "start_time": "2025-04-21T14:04:24.921744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokenise\n",
    "tokeniser = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokens = tokeniser(sentences, return_tensors=\"pt\", padding=True)"
   ],
   "id": "c20d9bfbd4cd0f05",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T14:04:25.673624Z",
     "start_time": "2025-04-21T14:04:25.250067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create embeddings\n",
    "transformer = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "embeddings = transformer(**tokens).last_hidden_state"
   ],
   "id": "2b8332446f816d6f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T14:04:25.718528Z",
     "start_time": "2025-04-21T14:04:25.682400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the query\n",
    "query = \"What is Python language suited for?\"\n",
    "query_tokens = tokeniser(query,\n",
    "                         return_tensors=\"pt\",\n",
    "                         padding='max_length',\n",
    "                         max_length=len(tokens.input_ids[0]))\n",
    "query_embeddings = transformer(**query_tokens).last_hidden_state"
   ],
   "id": "ed2675873b6bf21d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T14:04:25.785580Z",
     "start_time": "2025-04-21T14:04:25.727631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fine the most relevant sentences\n",
    "search_results = semantic_search(query_embeddings, embeddings, top_k=3)"
   ],
   "id": "6c0af457f24ff71b",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "self must be a matrix",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Fine the most relevant sentences\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m search_results = \u001B[43msemantic_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery_embeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_k\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/sentence_transformers/util.py:487\u001B[39m, in \u001B[36msemantic_search\u001B[39m\u001B[34m(query_embeddings, corpus_embeddings, query_chunk_size, corpus_chunk_size, top_k, score_function)\u001B[39m\n\u001B[32m    483\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m query_start_idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(query_embeddings), query_chunk_size):\n\u001B[32m    484\u001B[39m     \u001B[38;5;66;03m# Iterate over chunks of the corpus\u001B[39;00m\n\u001B[32m    485\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m corpus_start_idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(corpus_embeddings), corpus_chunk_size):\n\u001B[32m    486\u001B[39m         \u001B[38;5;66;03m# Compute cosine similarities\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m487\u001B[39m         cos_scores = \u001B[43mscore_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    488\u001B[39m \u001B[43m            \u001B[49m\u001B[43mquery_embeddings\u001B[49m\u001B[43m[\u001B[49m\u001B[43mquery_start_idx\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_start_idx\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_chunk_size\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    489\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcorpus_embeddings\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcorpus_start_idx\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mcorpus_start_idx\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mcorpus_chunk_size\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    490\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    492\u001B[39m         \u001B[38;5;66;03m# Get top-k scores\u001B[39;00m\n\u001B[32m    493\u001B[39m         cos_scores_top_k_values, cos_scores_top_k_idx = torch.topk(\n\u001B[32m    494\u001B[39m             cos_scores, \u001B[38;5;28mmin\u001B[39m(top_k, \u001B[38;5;28mlen\u001B[39m(cos_scores[\u001B[32m0\u001B[39m])), dim=\u001B[32m1\u001B[39m, largest=\u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;28msorted\u001B[39m=\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    495\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/NexusLLM/.venv/lib/python3.13/site-packages/sentence_transformers/util.py:108\u001B[39m, in \u001B[36mcos_sim\u001B[39m\u001B[34m(a, b)\u001B[39m\n\u001B[32m    106\u001B[39m a_norm = normalize_embeddings(a)\n\u001B[32m    107\u001B[39m b_norm = normalize_embeddings(b)\n\u001B[32m--> \u001B[39m\u001B[32m108\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmm\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma_norm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb_norm\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtranspose\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mRuntimeError\u001B[39m: self must be a matrix"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T14:05:42.395430Z",
     "start_time": "2025-04-21T14:05:42.390703Z"
    }
   },
   "cell_type": "code",
   "source": "embeddings.shape",
   "id": "1811177f4880ea3c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 14, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T14:05:45.581157Z",
     "start_time": "2025-04-21T14:05:45.578564Z"
    }
   },
   "cell_type": "code",
   "source": "query_embeddings.shape",
   "id": "66c6563d174c1025",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4f64e4172ba06eb9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nexusllm",
   "language": "python",
   "name": "nexusllm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

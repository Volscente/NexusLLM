{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c334d93-ff04-4ee2-956a-8bd184e877ee",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The notebook is intended to develop a character-based LLM trained on [Shakespeare Literature](https://github.com/karpathy/ng-video-lecture/blob/master/input.txt).\n",
    "\n",
    "**Resources**\n",
    "- [Reference tutorial from Andrej Karpathy](https://www.youtube.com/watch?v=kCc8FmEb1nY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d0ade33-2fe6-4a2f-9f05-3e973305b12a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Standard Libraries\n",
    "import os\n",
    "import tiktoken\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529f9811-274c-4084-8783-48590eca1fce",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f2ba6b6-2572-4769-baee-76e609d52c32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define local data file path\n",
    "data_file_path = Path(os.path.abspath('')).parents[1] / 'data' / 'character_based_llm_data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ad88529-29f5-4360-8044-f9f7fef40489",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "with open(data_file_path, 'r', encoding='utf-8') as data_file:\n",
    "    data = data_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0dffaaa-f1a4-4f99-ad1d-782c435ad4ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the vocabulary of characters in the data\n",
    "vocabulary = sorted(list(set(data)))\n",
    "vocabulary_size = len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67909db2-9f64-4a76-b5e3-109da6e37d5d",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60957e1e-328a-4beb-b32e-1fa6c689ac72",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "It is an important data preprocessing operation which converts the single portion of the sequence \n",
    "(characters or tokens of words) into numerical value based on all the possible values of the train vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f0b9c8-2c27-4408-a2a2-0ed083844aca",
   "metadata": {},
   "source": [
    "### Custom Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9790d9a8-e5f2-400e-8ac5-81d23317475e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# String to integer encoder\n",
    "string_integer_encoder = {character: integer for integer, character in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9490cb69-06c2-4189-9c29-d390dccd5009",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# String to integer decoder\n",
    "string_integer_decoder = {integer: character for integer, character in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f056b10-ab3b-4a62-a1e8-70c8aca1fea0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the encoder\n",
    "encoder = lambda string: [string_integer_encoder[character] for character in string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dc290e3-085b-421b-a13f-0618a8f960da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the decoder\n",
    "decoder = lambda integers_list: ''.join([string_integer_decoder[integer] for integer in integers_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33977d7c-3e37-4048-9817-64fdd8699797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a sample sentence\n",
    "tokeniser_sample_sentence = 'Hello there'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "987a6fc1-60bc-43e7-9486-7cd3cd798b71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of Encoding and Decoding\n",
      "Example sentence: Hello there\n",
      "Encode: [20, 43, 50, 50, 53, 1, 58, 46, 43, 56, 43]\n",
      "Decode: Hello there\n"
     ]
    }
   ],
   "source": [
    "print('Example of Encoding and Decoding')\n",
    "print('Example sentence: {}'.format(tokeniser_sample_sentence))\n",
    "print('Encode: {}'.format(encoder(tokeniser_sample_sentence)))\n",
    "print('Decode: {}'.format(decoder(encoder(tokeniser_sample_sentence))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9942d7eb-0538-4984-9292-c0d3c5b5b283",
   "metadata": {},
   "source": [
    "### TikToken\n",
    "\n",
    "There are also already available Tokenizer as [TikToken](https://github.com/openai/tiktoken) from OpenAI. The goal is the same: produce a numerical representation from a string sequence, but they are based over a different vocabulary and transform the sequence in a different manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92563305-172b-4a0f-b277-b155abf80f87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the Tokenizer\n",
    "tiktoken_tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8c2c8f8-163c-4eac-9de5-e54c7e24954c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Vocabularies of TikToken: 50257\n",
      "List of Vocabularies from Custom Tokenizer: 65\n"
     ]
    }
   ],
   "source": [
    "print('List of Vocabularies of TikToken: {}'.format(tiktoken_tokenizer.n_vocab))\n",
    "print('List of Vocabularies from Custom Tokenizer: {}'.format(vocabulary_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00b1a572-cdf1-4d98-89fd-7f632a572162",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of Encoding and Decoding\n",
      "Example sentence: Hello there\n",
      "Encode: [15496, 612]\n",
      "Decode: Hello there\n"
     ]
    }
   ],
   "source": [
    "print('Example of Encoding and Decoding')\n",
    "print('Example sentence: {}'.format(tokeniser_sample_sentence))\n",
    "print('Encode: {}'.format(tiktoken_tokenizer.encode(tokeniser_sample_sentence)))\n",
    "print('Decode: {}'.format(tiktoken_tokenizer.decode(tiktoken_tokenizer.encode(tokeniser_sample_sentence))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29179834-3679-4cad-a5ef-af20dded824a",
   "metadata": {},
   "source": [
    "### Tokenize the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd8c4db0-fcb9-42d7-a433-1756dc8aa587",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize the data and store it in a PyTorch Tensor\n",
    "data_encoded_tensor = torch.tensor(encoder(data), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a1ef6c5-785a-43d9-bc63-496207a48fc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115389]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(data_encoded_tensor.shape, data_encoded_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "114efac7-6539-4368-9059-94fc7c06521d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "# The entire data are represented as a sequence of integeres now\n",
    "print(data_encoded_tensor[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac56642-e9db-4af3-a9f2-7c00ed471c43",
   "metadata": {},
   "source": [
    "## Train & Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fae7c63e-8d99-4eb1-ae06-42606f8fa7a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the train percentage\n",
    "train_percentage = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a83385aa-2451-442f-a7c8-c0a69797bd71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split in train and validation data\n",
    "train_data = data_encoded_tensor[:int(train_percentage * len(data_encoded_tensor))]\n",
    "validation_data = data_encoded_tensor[int(train_percentage * len(data_encoded_tensor)):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9decac60-ed4f-411f-859b-d0fbc63a5535",
   "metadata": {},
   "source": [
    "## Blocks\n",
    "\n",
    "The training would be splitted into Blocks, which are sequence of characters randomly selected within the training data. The length of a single block is the Block Size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0468d5cc-8d9a-441d-9364-0af01296e425",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Block\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])\n",
      "First Cit\n"
     ]
    }
   ],
   "source": [
    "# Define the block_size\n",
    "block_size = 8\n",
    "\n",
    "print('First Block')\n",
    "print(train_data[:block_size + 1])\n",
    "print(data[:block_size + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13bd13f-c094-45e2-a6a5-dac50d735492",
   "metadata": {},
   "source": [
    "**NOTE:** \n",
    "Within each block, the transformer will learn multiple sequences at a time. \n",
    "- With [18], usually [47] comes next\n",
    "- With [18, 47], usually [56] comes next\n",
    "- With [18, 47, 56], usually [57] comes next\n",
    "- ...\n",
    "\n",
    "So everytime, in each block, there would be different sequences with different labels. The transformer will learn all of these sequences within a single block everytime. In this way, the Transformer will learn several contexts of different sizes and get used to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8be8109c-7abc-4c7c-9055-3345a4ac43d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When features are tensor([18]) the label is 47\n",
      "When features are tensor([18, 47]) the label is 56\n",
      "When features are tensor([18, 47, 56]) the label is 57\n",
      "When features are tensor([18, 47, 56, 57]) the label is 58\n",
      "When features are tensor([18, 47, 56, 57, 58]) the label is 1\n",
      "When features are tensor([18, 47, 56, 57, 58,  1]) the label is 15\n",
      "When features are tensor([18, 47, 56, 57, 58,  1, 15]) the label is 47\n",
      "When features are tensor([18, 47, 56, 57, 58,  1, 15, 47]) the label is 58\n"
     ]
    }
   ],
   "source": [
    "# Example of features and labels within each batch\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size + 1]\n",
    "\n",
    "for index in range(block_size):\n",
    "    \n",
    "    features = x[:index + 1]\n",
    "    label = y[index]\n",
    "    \n",
    "    print(f\"When features are {features} the label is {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d02241d-1f5c-4680-a7e4-fe622a2cd162",
   "metadata": {},
   "source": [
    "## Batches\n",
    "It is a set of blocks that are passed to the Transformer at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cafdec0-5148-47ce-9a51-133251b78aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10acf89b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the batch size\n",
    "batch_size = 4\n",
    "\n",
    "# Set Torch Seed\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "619c9a56-9d9e-4774-a3e3-904f681e8bef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_batch(data):\n",
    "    \"\"\"\n",
    "    Return the x and y for the passed dataset\n",
    "    \n",
    "    Args:\n",
    "        data: torch.Tensor input data\n",
    "    \n",
    "    Returns:\n",
    "        x: torch.Tensor features values x batch_size\n",
    "        y: torch.Tensor label values x batch_size\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the block index for each of the batch\n",
    "    block_indices = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    \n",
    "    # Retrieve x and y from the data\n",
    "    x = torch.stack([data[block_index:block_index + block_size] for block_index in block_indices])\n",
    "    y = torch.stack([data[block_index + 1:block_index + block_size + 1] for block_index in block_indices])\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25aeecbb-ee3f-41b9-9612-60df48fa212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve sample batches\n",
    "x_batch_sample, y_batch_sample = get_batch(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca2b1be5-2e67-4ab3-9934-536228399dae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Batch Sample Shape: torch.Size([4, 8])\n",
      "X Batch Sample Shape: torch.Size([4, 8])\n",
      "\n",
      "\n",
      "X First Batch Sample: tensor([59, 57,  1, 58, 56, 39, 47, 58])\n",
      "Y First Batch Sample: tensor([57,  1, 58, 56, 39, 47, 58, 53])\n"
     ]
    }
   ],
   "source": [
    "print(f\"X Batch Sample Shape: {x_batch_sample.shape}\")\n",
    "print(f\"X Batch Sample Shape: {y_batch_sample.shape}\")\n",
    "print('\\n')\n",
    "print(f\"X First Batch Sample: {x_batch_sample[0]}\")\n",
    "print(f\"Y First Batch Sample: {y_batch_sample[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620bcad7-77cf-401a-900f-2027404806b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Each batch has 8 indpendent data samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cd6cb0-6bc2-44ab-a8c9-3d9de2393de3",
   "metadata": {},
   "source": [
    "# Bigram Language Model\n",
    "\n",
    "This is the simplest kind of Neural Network model you can imagine. We're going to implement it from PyTorch based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d5633a7-5a66-420b-bbce-ea23f448e93e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10acf89b0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set Torch Seed\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ac08f7c-a0f0-4ef4-99a8-8bd5367757e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocabulary_size):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # Create a Token Embedding Table, which is a matrix vocabulary_size x vocabulary_size\n",
    "        self.token_embedding_table = nn.Embedding(vocabulary_size, vocabulary_size)\n",
    "        \n",
    "    def forward(self, index, targets=None):\n",
    "    \n",
    "        # When passing an index to the token_embedding_table, it will return that specific row next characters logits (probabilities)\n",
    "        # In a (Batch, Times, Channels) fashion -> torch.Size([4, 8, 65])\n",
    "        logits = self.token_embedding_table(index)\n",
    "        \n",
    "        # Compute the loss in case there are the target labels\n",
    "        if targets is None:\n",
    "            \n",
    "            loss = None\n",
    "            \n",
    "        else:\n",
    "        \n",
    "            # Beore calculating the loss of the logits, we need to reshape them, because the cross_entropy function expects a (Batch, Channels, Times) input\n",
    "            # Get the logits shape\n",
    "            batch_dim, times_dim, channels_dim = logits.shape\n",
    "\n",
    "            # Reshape the logits\n",
    "            logits = logits.view(batch_dim * times_dim, channels_dim)\n",
    "\n",
    "            # Reshape the targets as well\n",
    "            targets = targets.view(batch_dim * times_dim)\n",
    "\n",
    "            # Measure the quality of the logits predictions\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        \"\"\"\n",
    "        Generates new tokens for the given maximum dimension, thus predicting the very next character\n",
    "        \"\"\"\n",
    "        \n",
    "        # index is a (B, T) array\n",
    "        for _ in range(max_new_tokens):\n",
    "            \n",
    "            # Get predictions (B, T, C)\n",
    "            logits, loss = self(index)\n",
    "            \n",
    "            # Select only the predictions in the last element (B, C)\n",
    "            # NOTE: This is not correct, because you should feed the entire sequence up to the last element, and not just the last one.\n",
    "            logits = logits[:, -1, :]\n",
    "            \n",
    "            # Get probabilities through the Softmax function (B, C)\n",
    "            probabilities = F.softmax(logits, dim=-1)\n",
    "            \n",
    "            # Sample from the distribution (B, 1) and obtain the next index character for all the batches\n",
    "            index_next_character = torch.multinomial(probabilities, num_samples=1)\n",
    "            \n",
    "            # Append the sampled index of the next character to the sequence (B, T+1)\n",
    "            index = torch.cat((index, index_next_character), dim=1)\n",
    "            \n",
    "        return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c8ef925-9f9e-4c55-bdc0-d8674cefd425",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instance the Bigram language Model\n",
    "bigram_language_model = BigramLanguageModel(vocabulary_size=vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62c69c55-a688-4528-b8a4-42d502cd160f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the logits and the loss for a single batch data sample\n",
    "logits, loss = bigram_language_model(x_batch_sample, targets=y_batch_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "036a763f-9e25-451e-ade3-b2e90541aef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 65])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc35814e-dfbe-40b4-a2c8-1015d669a621",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.5242, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2222da13-bd46-4e9f-8002-1144298fb91d",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16b18108-fab5-4f60-b159-9d39ead2f789",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate the a 1 x 1 Tensor holding a zero value (It corresponds to 'new line' character)\n",
    "# It would be our first character that will kick off the generation\n",
    "initial_seed = torch.zeros((1, 1), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e0bfd04-9b78-47c8-bdf9-0843a540dbdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
     ]
    }
   ],
   "source": [
    "# Generate 100 more characters ('max_new_tokens=100')\n",
    "# Retrieve the first and alone batch ('[0]')\n",
    "print(decoder(bigram_language_model.generate(initial_seed, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44239a57-6016-4096-9316-4e24188d7143",
   "metadata": {},
   "source": [
    "As expecting, the output is crap. That's also because, in order to generate the 'f' character at the 7th position, only the previous character, ':', has been fed. Insted, all the sequence 'Qd&!e:' should be ingested to predict the next element and not only the last one.  This refers to the 'NOTE' warning in the generate function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1426f711-36e2-4045-8f92-65b5a385eea0",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21788b74-25c1-420b-8937-284bfce42edb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the Optimizer\n",
    "optimizer = torch.optim.AdamW(bigram_language_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ea92359-d4d4-4ba2-995c-14ceb59fbc6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 - Loss: 4.7736\n",
      "Step: 1000 - Loss: 3.7155\n",
      "Step: 2000 - Loss: 3.1113\n",
      "Step: 3000 - Loss: 2.8313\n",
      "Step: 4000 - Loss: 2.487\n",
      "Step: 5000 - Loss: 2.5177\n",
      "Step: 6000 - Loss: 2.5832\n",
      "Step: 7000 - Loss: 2.5644\n",
      "Step: 8000 - Loss: 2.4895\n",
      "Step: 9000 - Loss: 2.5055\n",
      "Step: 9999 - Loss: 2.3863\n"
     ]
    }
   ],
   "source": [
    "# Increase the batch size from 4 to 32\n",
    "batch_size = 32\n",
    "\n",
    "# Loop over 100 iterations\n",
    "for step in range(10000):\n",
    "    \n",
    "    # Sample data\n",
    "    x_batch, y_batch = get_batch(train_data)\n",
    "    \n",
    "    # Evaluate the loss\n",
    "    logits, loss = bigram_language_model(x_batch, y_batch)\n",
    "    \n",
    "    # Reset the gradient\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    \n",
    "    # Backpropagate the error and getting the gradients for all the weights\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print the loss every 100 steps\n",
    "    if step % 1000 == 0:\n",
    "        print(f'Step: {step} - Loss: {round(loss.item(), 4)}')\n",
    "        \n",
    "print(f'Step: {step} - Loss: {round(loss.item(), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213a2ece-ab05-4278-a61c-0651f478aebf",
   "metadata": {},
   "source": [
    "As we can see, the loss is going down slowly.\n",
    "\n",
    "<br>\n",
    "\n",
    "However, this loss is not really precise, because it depends on the batch on which it is calculated. With the Estimate Loss, we want to estimate the loss over multiple batches through the average."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1287321-d8a3-49d2-b774-c57542a02b88",
   "metadata": {},
   "source": [
    "## Example after Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d76d247b-98c7-4c53-b2b0-496fb068e512",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iyoteng h hasbe pave pirance\n",
      "RDe hicomyonthar's\n",
      "PlinseKEd ith henouratucenonthioneir thondy, y heltieiengerofo'dsssit ey\n",
      "KIN d pe wither vouprrouthercc.\n",
      "hathe; d!\n",
      "My hind ttid?\n",
      "ig t ouchos tes; st yo hind wotin grotonear 'so it t jod weancotha:\n",
      "h haybet--s n prids, r loncave w hollular s O:\n",
      "HIs; ht anjx?\n",
      "\n",
      "DUThinqunt.\n",
      "\n",
      "LaZAnde.\n",
      "athave l.\n",
      "KEONH:\n",
      "ARThanco be y,-hedarwnoddy scar t tridesar, wnl'shenou\n"
     ]
    }
   ],
   "source": [
    "# Generate again 400 tokens and let's see the improvement\n",
    "print(decoder(bigram_language_model.generate(initial_seed, max_new_tokens=400)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07b7014-aa92-4b10-98c8-819a8393f11b",
   "metadata": {},
   "source": [
    "Much better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc0c33c-ddcf-4b30-85d7-e5493d7aec0d",
   "metadata": {},
   "source": [
    "# Self-Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d369ea-6efc-44a3-96cb-7bbf94f4b167",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a93b083-7028-41e4-8d15-a426de18c39b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10acf89b0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seed\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "724b084d-20e2-4f97-92b2-b0788a10509e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define dimensions\n",
    "batch_size = 4\n",
    "token_size = 8\n",
    "channel_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b432d58d-ca38-43a8-8236-ef2d2679d9a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a Batch, Tokens, Channels tensor\n",
    "# NOTE: Channels is the content of each token (i.e., 2 numberes)\n",
    "self_attention_tensor = torch.randn(batch_size, token_size, channel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b95b7f3-2b44-48ae-b94d-593ee0211211",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_attention_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae19252-9fb4-44e1-9a82-5a157a50b4a0",
   "metadata": {},
   "source": [
    "We would like now to make the 8 tokens in each batch to \"talk\" with each other.\n",
    "\n",
    "<br>\n",
    "\n",
    "Given the following token: `[1, 2, 3, 4, 5, 6, 7, 8]` we want to establish a communicaton between the tokens in a very specific way.\n",
    "The token `5` should be able to communicate with tokens `[1, 2, 3, 4]`, but not with `[6, 7, 8]`. That's because they are **Future Tokens**.\n",
    "\n",
    "<br>\n",
    "\n",
    "How can we make such communication to happen? For the token `5`, we can think of just make the average of what comes before `[1, 2, 3, 4]`. Such average would become a sort of Feature Vector that summarise the token `5` in the context of his previous tokens. However we will lost lot of information with just an average."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd40ca9-aa7d-47fb-adbc-52c75c20228c",
   "metadata": {},
   "source": [
    "## For Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b85a333-a0f0-49c5-a523-760ab1ee4323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the empty Feature Vector\n",
    "# NOTE: Bag of Words is a term used when average stuff together\n",
    "tensor_bag_of_words = torch.zeros((4, 8, 2))\n",
    "\n",
    "# Populate the bag of words\n",
    "for batch in range(batch_size):\n",
    "    for token in range(token_size):\n",
    "        \n",
    "        # Retrieve previous tokens for the current batch\n",
    "        # Shape is (Tokens, Channels)\n",
    "        previous_tokens = self_attention_tensor[batch, :token+1]\n",
    "        \n",
    "        # Compute the mean and store it in the bag of words\n",
    "        # Mean over the 0-dimension (i.e., the tokens)\n",
    "        tensor_bag_of_words[batch, token] = torch.mean(previous_tokens, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39e0fb1-237a-4d74-8b5a-52eead51a960",
   "metadata": {},
   "source": [
    "Let's analyse the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "106ba57b-c96d-42d5-8b9f-4bde287a43ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.3596, -0.9152],\n",
      "        [ 0.6258,  0.0255],\n",
      "        [ 0.9545,  0.0643],\n",
      "        [ 0.3612,  1.1679],\n",
      "        [-1.3499, -0.5102],\n",
      "        [ 0.2360, -0.2398],\n",
      "        [-0.9211,  1.5433]])\n",
      "\n",
      "\n",
      "Bag of Words\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n"
     ]
    }
   ],
   "source": [
    "print('Original Tensor')\n",
    "print(self_attention_tensor[0])\n",
    "print('\\n')\n",
    "print('Bag of Words')\n",
    "print(tensor_bag_of_words[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359b4b87-3487-4786-82e6-b5fcc42d7ab6",
   "metadata": {},
   "source": [
    "The first element is the same, because it has no previous context to average except for itself.\n",
    "\n",
    "However, the second element from the Bag of Words, is the average of itself and the previous one.\n",
    "\n",
    "This technique is quite inefficient, since we are using a for loop. Let's now see how to exploit matrix multiplication properties to speed up the computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f6c87b-de2f-44ac-9e6a-5fe07a29622d",
   "metadata": {},
   "source": [
    "## Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09cd12f0-ac71-4c7b-a0b0-a4b54e4138fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix 1\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "Matrix 2\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "Matrix 3\n",
      "tensor([[14., 16.],\n",
      "        [14., 16.],\n",
      "        [14., 16.]])\n"
     ]
    }
   ],
   "source": [
    "# Let's see an example of matrix multiplication\n",
    "torch.manual_seed(42)\n",
    "matrix_1 = torch.ones(3, 3)\n",
    "matrix_2 = torch.randint(0, 10, (3, 2)).float()\n",
    "matrix_3 = matrix_1 @ matrix_2\n",
    "\n",
    "print('Matrix 1')\n",
    "print(matrix_1)\n",
    "print('Matrix 2')\n",
    "print(matrix_2)\n",
    "print('Matrix 3')\n",
    "print(matrix_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f4c656-49ff-4d45-8c21-0620090f6083",
   "metadata": {},
   "source": [
    "The element [0, 0] in `matrix_3` is `14` and it is because the first row of `matrix_1` is multiplied and added to the first column of `matrix_2`. Thus, `2*1 + 6*1 + 6*1 = 14`.\n",
    "\n",
    "There is an interesting function in PyTorch to return a triangle matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70400b5b-9278-481f-bc51-b4f8bbdadcaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Triangle matrix\n",
    "torch.tril(torch.ones(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2c626e0-4fbc-4abe-b218-d8f020f032c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix 1\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "Matrix 2\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "Matrix 3\n",
      "tensor([[ 2.,  7.],\n",
      "        [ 8., 11.],\n",
      "        [14., 16.]])\n"
     ]
    }
   ],
   "source": [
    "# Let's use the triangle matrix instead of the ones\n",
    "torch.manual_seed(42)\n",
    "matrix_1 = torch.tril(torch.ones(3, 3))\n",
    "matrix_2 = torch.randint(0, 10, (3, 2)).float()\n",
    "matrix_3 = matrix_1 @ matrix_2\n",
    "\n",
    "print('Matrix 1')\n",
    "print(matrix_1)\n",
    "print('Matrix 2')\n",
    "print(matrix_2)\n",
    "print('Matrix 3')\n",
    "print(matrix_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f65472d-0030-4d32-ad24-4a7e4a994bb7",
   "metadata": {},
   "source": [
    "We can see now see that in `matrix_3` the first row stays the same, while the second row is only sonsidering the first two rows of `matrix_2` and the third row of `matrix_3` is considering all the rows. This is the exact same behaviour that has been implemented with the Foor Loop before.\n",
    "\n",
    "To replicate the exact same behaviour as in the Foor Loop, we need at last to make the average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "935f1889-7475-477a-b8cf-4f75caaba33a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix 1\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "Matrix 2\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "Matrix 3\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# Let's incorporate also the average\n",
    "torch.manual_seed(42)\n",
    "matrix_1 = torch.tril(torch.ones(3, 3))\n",
    "matrix_1 = matrix_1 / torch.sum(matrix_1, 1, keepdim=True)\n",
    "matrix_2 = torch.randint(0, 10, (3, 2)).float()\n",
    "matrix_3 = matrix_1 @ matrix_2\n",
    "\n",
    "print('Matrix 1')\n",
    "print(matrix_1)\n",
    "print('Matrix 2')\n",
    "print(matrix_2)\n",
    "print('Matrix 3')\n",
    "print(matrix_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4c4b0b-5e66-4580-974a-345ba9b2efb9",
   "metadata": {},
   "source": [
    "Now the element [1, 0] of the `matrix_3` (4) is the exact average of the first two elements of the first column of `matrix_2`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ca0af2-a8a4-4386-a9b6-83c5c33d3c02",
   "metadata": {},
   "source": [
    "## Vectorized Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b849be11-7c56-4ad5-8432-8c2778bb05b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the averaged triangle matrix (NOTE: shape is the token_size\n",
    "weights_triangle_matrix = torch.tril(torch.ones(token_size, token_size))\n",
    "averaged_weights_triangle_matrix = weights_triangle_matrix / weights_triangle_matrix.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73ebee57-93dc-41e9-a6fa-bbd463b83797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaged_triangle_matrix is a (T, T) matrix\n",
    "# PyTorch will automatically transform it into (B, T, T) when doing the dot product with 'self_attention_tensor'\n",
    "# All the batches B would be multiplied at the same time, by doing (T, T) x (T, C)\n",
    "vecotirzed_tensor_bag_of_words = averaged_weights_triangle_matrix @ self_attention_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "91c04b6e-3b7c-4d54-9a21-6ff7cf3dc0e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecotirzed_tensor_bag_of_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b84be49-fa15-4e3b-8a1a-9090a46dcf1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the methods For Loop and Vectorization are the same\n",
    "torch.allclose(tensor_bag_of_words, vecotirzed_tensor_bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753b5d3b-ae17-4528-ae8d-d517c418e6ca",
   "metadata": {},
   "source": [
    "We just did a weighted aggregated sum in order to compute the context of each token with respect to its previous steps in the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28103de-658a-480b-aebd-fdac76d5d238",
   "metadata": {},
   "source": [
    "## Vectorized Softmax Implementation\n",
    "\n",
    "The final results would be exaclty the same as before, but let's see why this version is a bit more interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ec6f2d8-7bd2-46f8-8743-b90dc013b470",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the ones (T, T) matrix\n",
    "triangle_ones_matrix = torch.tril(torch.ones(token_size, token_size))\n",
    "triangle_ones_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "748831c0-55d1-4421-880a-7596d6ddef8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the weights matrix\n",
    "weights_matrix = torch.zeros(token_size, token_size)\n",
    "weights_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d0885668-dc96-410c-8c0e-b4af74be3d61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's initialise th weights_matrix\n",
    "# NOTE: '-inf' indicates that the token should not communicate with that future step in the sequence\n",
    "# NOTE: '0' is the initial weight that the step gives to the previous step in the sequence it can communicate with\n",
    "weights_matrix = weights_matrix.masked_fill(triangle_ones_matrix == 0, float('-inf'))\n",
    "weights_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85525996-7a94-492b-aa2d-f55495bc4b2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's apply Softmax function to obtain the same result as before in Vectorized Implementation\n",
    "weights_matrix = F.softmax(weights_matrix, dim=1)\n",
    "weights_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a90a910d-ae26-497c-b494-15ee5c5e2494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply matrix multiplication\n",
    "vecotirzed_softmax_tensor_bag_of_words = weights_matrix @ self_attention_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d911b5ea-0f0d-44c2-bc76-0028424b0fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify they are the same\n",
    "torch.allclose(vecotirzed_tensor_bag_of_words, vecotirzed_softmax_tensor_bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7db734-207d-4520-921a-5aa4fcdb4f1c",
   "metadata": {},
   "source": [
    "The zeros in the initial weights matrix represents the importance the specific token is given to another token. After the training, the tokens will start finding other tokens interesting and will assign them a different value with respect to zero. This is the base of Self-Attention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a438bde-2313-40af-89be-af1412d80172",
   "metadata": {},
   "source": [
    "# Updated Bigram Language Model\n",
    "\n",
    "Let's create an updated version of the Bigram Language Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0fb1e0e8-4238-43c5-b78e-20fb5755f886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the number of embeddings\n",
    "number_embeddings = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab5c49f3-0f88-4d49-a07f-43bbaf2f60b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UpdatedBigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # Create a Token Embedding Table -> Encode the token\n",
    "        self.token_embedding_table = nn.Embedding(vocabulary_size, number_embeddings)\n",
    "        \n",
    "        # Create an Index Embedding Table -> Encode the token's index\n",
    "        self.position_embedding_table = nn.Embedding(block_size, number_embeddings)\n",
    "        \n",
    "        \n",
    "        # Define a linear layer to retrieve the logits from the token embeddings\n",
    "        self.linear_layer = torch.nn.Linear(number_embeddings, vocabulary_size)\n",
    "        \n",
    "    def forward(self, index, targets=None):\n",
    "        \n",
    "        # Retrieve batch size and times size from the shape\n",
    "        batch_dim, times_dim = index.shape\n",
    "    \n",
    "        # Retrieve the token embeddings\n",
    "        token_embeddings = self.token_embedding_table(index)\n",
    "        \n",
    "        # Retrieve index embeddings\n",
    "        position_embeddings = self.position_embedding_table(torch.arange(times_dim))\n",
    "        \n",
    "        # Compute the input to the linear layer\n",
    "        # NOTE: 'x' would not just hold the token identities, but also the position at which the token occurs\n",
    "        x = token_embeddings + position_embeddings\n",
    "        \n",
    "        # Compute the logits\n",
    "        logits = self.linear_layer(x) # (B, T, vocabulary_size)\n",
    "        \n",
    "        # Compute the loss in case there are the target labels\n",
    "        if targets is None:\n",
    "            \n",
    "            loss = None\n",
    "            \n",
    "        else:\n",
    "        \n",
    "            # Beore calculating the loss of the logits, we need to reshape them, because the cross_entropy function expects a (Batch, Channels, Times) input\n",
    "            # Get the logits shape\n",
    "            batch_dim, times_dim, channels_dim = logits.shape\n",
    "\n",
    "            # Reshape the logits\n",
    "            logits = logits.view(batch_dim * times_dim, channels_dim)\n",
    "\n",
    "            # Reshape the targets as well\n",
    "            targets = targets.view(batch_dim * times_dim)\n",
    "\n",
    "            # Measure the quality of the logits predictions\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        \"\"\"\n",
    "        Generates new tokens for the given maximum dimension, thus predicting the very next character\n",
    "        \"\"\"\n",
    "        \n",
    "        # index is a (B, T) array\n",
    "        for _ in range(max_new_tokens):\n",
    "            \n",
    "            # Get predictions (B, T, C)\n",
    "            logits, loss = self(index)\n",
    "            \n",
    "            # Select only the predictions in the last element (B, C)\n",
    "            # NOTE: This is not correct, because you should feed the entire sequence up to the last element, and not just the last one.\n",
    "            logits = logits[:, -1, :]\n",
    "            \n",
    "            # Get probabilities through the Softmax function (B, C)\n",
    "            probabilities = F.softmax(logits, dim=-1)\n",
    "            \n",
    "            # Sample from the distribution (B, 1) and obtain the next index character for all the batches\n",
    "            index_next_character = torch.multinomial(probabilities, num_samples=1)\n",
    "            \n",
    "            # Append the sampled index of the next character to the sequence (B, T+1)\n",
    "            index = torch.cat((index, index_next_character), dim=1)\n",
    "            \n",
    "        return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a470c7-e96d-4be1-9abc-e717235a2463",
   "metadata": {},
   "source": [
    "# Improved Self-Attention\n",
    "\n",
    "Previously we implemented a Self-Attention mechanism based on just the average of the previous token sequence and the current token. This is not a great approach, since we are expecting there are tokens that would be more important for other token with respect to the others. \n",
    "\n",
    "In order to let the tokens discover other interesting tokens, each of them will have two things:\n",
    "- Query Vector - \"What I am looking for\"\n",
    "- Key Vector - \"What do I contain\"\n",
    "\n",
    "Now, by doing the Dot Product as we did before, reasonating queries and keys will be matched and have a high value. This will be our new `weights_matrix`.\n",
    "\n",
    "We are going to implement what is called a **Single Head Self-Attention Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55495a45-df9e-4398-9994-abdf570957d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56f9ab2-e0f6-42e9-87f1-70b7f7c01922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

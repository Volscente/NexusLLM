<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Embeddings - NexusLLM</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Embeddings";
        var mkdocs_page_input_path = "embeddings.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> NexusLLM
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">NexusLLM</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../transformers/">Transformers</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../tokenizers/">Tokenizer</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="#">Embeddings</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#definition">Definition</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#usage">Usage</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#semantic-search">Semantic Search</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#applications">Applications</a>
    </li>
        </ul>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../vector_search/">Vector Search</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../LLMs/">LLMs</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../google_llms/">Google LLMs</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../fine_tuning/">Fine-Tuning</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../evaluation/">LLMs Evaluation</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../deepeval/">DeepEval</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../LLMOps/">LLMOps</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../agents/">Agents</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">NexusLLM</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Embeddings</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/Volscente/NexusLLM/edit/master/docs/embeddings.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="embeddings">Embeddings</h1>
<h2 id="definition">Definition</h2>
<p>Embeddings are numerical representations of real-world data such as text,
speech, image, or videos. They are expressed as low-dimensional vectors where the
geometric distances of two vectors in the vector space is a projection of the relationships
between the two real-world objects that the vectors represent.</p>
<p>Such low dimensional representation try to preserve the most of the "essential information" of the
original objects.</p>
<p>Ideally the embeddings are created, so they place objects with similar semantic properties
closer in the embedding space.</p>
<p>The Embeddings are usually obtained through different ML models, like Encoder-based Transformers such as BERT.</p>
<h2 id="usage">Usage</h2>
<h3 id="semantic-search">Semantic Search</h3>
<ol>
<li>Precomputing the embeddings for billions items of the search space.</li>
<li>Mapping query embeddings to the same embedding space.</li>
<li>Efficient computing and retrieving of the nearest neighbors of the query embeddings in
the search space.</li>
</ol>
<h3 id="applications">Applications</h3>
<ul>
<li>Retrieval</li>
<li>Recommendations</li>
<li>Features for ML Models</li>
</ul>
<h1 id="types-of-embeddings">Types of Embeddings</h1>
<h2 id="text-embeddings">Text Embeddings</h2>
<h3 id="definition_1">Definition</h3>
<p>They are created through a process:
1. Tokenisation
2. indexing
3. Embedding</p>
<h2 id="word-embeddings">Word Embeddings</h2>
<h3 id="usage_1">Usage</h3>
<p>Word embeddings can be directly used in some downstream tasks like Named Entity
Recognition (NER).</p>
<h3 id="technologies">Technologies</h3>
<ul>
<li>GloVe</li>
<li>SWIVEL</li>
<li>Word2Vec</li>
</ul>
<h3 id="word2vec">Word2Vec</h3>
<p>Word2Vec is a family of model architectures that operates on the principle of “the semantic
meaning of a word is defined by its neighbors”.</p>
<p>It uses a matrix of shape (size_of_vocabulary, size_of_each_embedding). 
This matrix can be used as a lookup table after the training process is completed using one of the following methods:
- The Continuous bag of words (CBOW)  is fast to train and is slightly more accurate for frequent words.
- The skip-gram is inverse of that of CBOW, with the middle word
being used to predict the surrounding words within a certain range. This approach is
slower to train but works well with small data and is more accurate for rare words.</p>
<p><img alt="CBOW &amp; Skip-Gram" src="../images/cbow_skip_gram.png" /></p>
<h3 id="glove">GloVe</h3>
<p>It uses a co-occurrence matrix, which represents the relationships between words. 
Then GloVe then uses a factorization technique to learn word representations
from the co-occurrence matrix.</p>
<h3 id="swivel">SWIVEL</h3>
<p>Unlike GloVE, it uses local windows to learn the word vectors by taking into
account the co-occurrence of words within a fixed window of its neighboring words.</p>
<p>It is slightly less accurate than GloVe on average, but is considerably faster to train.</p>
<h2 id="document-embeddings">Document Embeddings</h2>
<h3 id="definition_2">Definition</h3>
<p>The evolution of the embeddings models can mainly be
categorized into two stages: shallow Bag-of-words (BoW) models and deeper pretrained
large language models (e.g., BERT).</p>
<h3 id="shallow-bow-models">Shallow BoW Models</h3>
<p>Early document embedding works follow the bag-of-words (BoW) paradigm, assuming a
document is an unordered collection of words. These early works include latent semantic
analysis (LSA)7 and latent dirichlet allocation (LDA).</p>
<p>Another famous bag-of-words family of document embeddings is TF-IDF.</p>
<p>It has two major weaknesses: both the word  ordering and the semantic meanings are ignored. 
BoW models fail to capture the sequential relationships between words.</p>
<h2 id="image-multimodal-embeddings">Image &amp; Multimodal Embeddings</h2>
<h3 id="computation">Computation</h3>
<p>Unimodal image embeddings can be derived in many ways: one of which is by training a
CNN or Vision Transformer model on a large scale image classification task (for example,
Imagenet), and then using the penultimate layer as the image embedding.</p>
<h2 id="structured-data-embeddings">Structured Data Embeddings</h2>
<h3 id="definition_3">Definition</h3>
<p>Unlike unstructured data, where a pre-trained embedding model is typically available, we
have to create the embedding model for the structured data since it would be specific to
a particular application.</p>
<h3 id="general-computation">General Computation</h3>
<p>Use dimensionality reductions techniques such as PCA.</p>
<h2 id="graph-embeddings">Graph Embeddings</h2>
<h3 id="definition_4">Definition</h3>
<p>Graph embeddings are another embedding technique that lets you represent not
only information about a specific object but also its neighbors.</p>
<h1 id="training">Training</h1>
<h2 id="two-tower-architecture">Two Tower Architecture</h2>
<p>Current embedding models usually use dual encoder (two tower) architecture. For example,
for the text embedding model used in question-answering, one tower is used to encode
the queries and the other tower is used to encode the documents.</p>
<p><img alt="Two Tower Architecture" src="../images/two_tower_architecture.png" /></p>
<p>The training includes a pretraining (unsupervised learning) and fine tuning (supervised
learning). Nowadays, the embedding models are usually directly initialized from foundation
models such as BERT, T5, GPT, Gemini, CoCa.</p>
<h1 id="applications_1">Applications</h1>
<h2 id="semi-categorical-text">Semi-Categorical Text</h2>
<ul>
<li>Suppose you have a column "Location" with entries that are not coherent (e.g., "US", "USA", United States", etc.</li>
<li>It is possible to use directly the Text Embeddings possibility</li>
</ul>
<h2 id="text-embeddings_1">Text Embeddings</h2>
<h3 id="sentencetransformer">SentenceTransformer</h3>
<ul>
<li>The solution is preferable when a plug-and-play model is needed.</li>
<li>It does not require pre-tokenisation and post-distillation (e.g., MeanPooling)</li>
<li>PCA can be applied to the output</li>
</ul>
<pre><code class="language-python">from sentence_transformers import SentenceTransformer
from sklearn.decomposition import PCA

model = SentenceTransformer(&quot;all-MiniLM-L6-v2&quot;)
sentence_embeddings = model.encode(texts, convert_to_numpy=True)

pca = PCA(n_components=64)
reduced_embeddings = pca.fit_transform(sentence_embeddings)
</code></pre>
<h3 id="autotokenizer-automodel">AutoTokenizer + AutoModel</h3>
<ul>
<li>The solution is preferable when it is needed more customisation and control over the embedding process</li>
<li>It requires pre-tokenisation and post-distillation</li>
<li>PCA can be applied to the output</li>
</ul>
<pre><code class="language-python">from transformers import AutoTokenizer, AutoModel
import torch
from sklearn.decomposition import PCA

tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')
model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')

inputs = tokenizer(&quot;This is a sentence.&quot;, return_tensors='pt')
outputs = model(**inputs)

# Get token embeddings (shape: [1, seq_len, hidden_dim])
token_embeddings = outputs.last_hidden_state

# Mean pooling (manual)
attention_mask = inputs['attention_mask']
mask = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
pooled = torch.sum(token_embeddings * mask, 1) / torch.clamp(mask.sum(1), min=1e-9)

pca = PCA(n_components=64)
reduced_embeddings = pca.fit_transform(pooled)
</code></pre>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../tokenizers/" class="btn btn-neutral float-left" title="Tokenizer"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../vector_search/" class="btn btn-neutral float-right" title="Vector Search">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/Volscente/NexusLLM" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../tokenizers/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../vector_search/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>

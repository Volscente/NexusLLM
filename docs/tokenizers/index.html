<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Tokenizer - NexusLLM</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Tokenizer";
        var mkdocs_page_input_path = "tokenizers.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> NexusLLM
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">NexusLLM</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../transformers/">Transformers</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="#">Tokenizer</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#resources">Resources</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#youtube">YouTube</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#playground">Playground</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#libraries">Libraries</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#definition">Definition</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#strings-and-unicode-in-python">Strings and Unicode in Python</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#common-problems">Common Problems</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#diluted-tokens">Diluted Tokens</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#whitespace-character">Whitespace Character</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#characteristics">Characteristics</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#tokens-vocabulary">Tokens Vocabulary</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#splitting">Splitting</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#techniques">Techniques</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#byte-pair-encoding-bpe">Byte Pair Encoding (BPE)</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#special-tokens">Special Tokens</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#training">Training</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#general">General</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#libraries_1">Libraries</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#sentencepiece">SentencePiece</a>
    </li>
        </ul>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../embeddings/">Embeddings</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../vector_search/">Vector Search</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../LLMs/">LLMs</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../google_llms/">Google LLMs</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../fine_tuning/">Fine-Tuning</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../evaluation/">LLMs Evaluation</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../deepeval/">DeepEval</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../LLMOps/">LLMOps</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../agents/">Agents</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">NexusLLM</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Tokenizer</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/Volscente/NexusLLM/edit/master/docs/tokenizers.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="tokenizer">Tokenizer</h1>
<h2 id="resources">Resources</h2>
<h3 id="youtube">YouTube</h3>
<ul>
<li><a href="https://www.youtube.com/watch?v=zduSFxRajkE">Let's build the GPT Tokenizer</a></li>
</ul>
<h3 id="playground">Playground</h3>
<ul>
<li><a href="https://tiktokenizer.vercel.app/">TikTokenizer</a></li>
</ul>
<h3 id="libraries">Libraries</h3>
<ul>
<li><a href="https://github.com/openai/tiktoken">TikToken</a></li>
<li><a href="https://github.com/google/sentencepiece">SentencePiece</a></li>
</ul>
<h2 id="definition">Definition</h2>
<p>It is used the main element while using LLMs, and it converts strings into vectors.</p>
<h2 id="strings-and-unicode-in-python">Strings and Unicode in Python</h2>
<p>In Python you can retrieve the Unicode value of a character through <code>ord('&lt;char&gt;)</code>.</p>
<p>The Python interpreter does not therefore see characters, but those numbers instead.</p>
<p>UTF-8/16/32 are specific encoding of Unicode: they define how to represent Unicode characeters in bytes.
For example: <code>'hello'.encode('utf-8')</code> would return the bytes for those 5 characters.</p>
<pre><code class="language-python">list('Hello'.encode('utf-8'))# [72, 101, 108, 108, 111] -&gt; List of raw bytes
</code></pre>
<p>UTF-8 uses dynamic number of bytes up to 4, while UTF-16 and UTF-32 use always the same amount of 4 bytes, 
leading to many 0s in their encodings, especially for single english characters.</p>
<p>It would be amazing to directly feed bytes into an LLM, but the context window would be too high! Therefore, we still
need the tokenization process.</p>
<h2 id="common-problems">Common Problems</h2>
<h3 id="diluted-tokens">Diluted Tokens</h3>
<p>The reason why LLMs work in different ways between different languages and/or topics,
is because of the Tokenizer (most of the time).</p>
<p>This can be due to different reasons, but if we have a look on how GPT2 Tokenizer behaves
with Korean with respect to english, we can see an interesting pattern. The tokens required
to tokenize a Korean text are much more than the ones required to tokenize a similar 
english text. This is because the tokenizer has been trained on english text mainly.</p>
<p>The effect is that the output tokens for the Korean text are much more sparse, and therefore
the LLM does not work very well.</p>
<h3 id="whitespace-character">Whitespace Character</h3>
<p>One key component while tokenizing code text is how to tokenize space. GPT2 use a single token for
each space, leading to a Diluted Tokens problem.</p>
<p>GPT4o Tokenizer (cl100k_base) improved this behaviour by using less tokens for the indentation.</p>
<h2 id="characteristics">Characteristics</h2>
<h3 id="tokens-vocabulary">Tokens Vocabulary</h3>
<p>It represents the tokens space through which the tokenizer can convert the text.
The bigger is this vocabulary, the lesser tokens would be required to tokenize a text.</p>
<p>More tokens in the vocabulary means that the tokenizer would be able to better represent the
meaning of a text, fighting the "Diluted Tokens" problem.</p>
<p>However, too big vocabulary might influence the LLM softmax function for the token sampling
while constructing its output.</p>
<h3 id="splitting">Splitting</h3>
<p>The very first step of any Encoder is the text split.</p>
<p>GPT-2, for example, does that through a REGEX, which can work differently between lowercase and uppercase.
Also, the way in which the sentence is separated before encoding it can affect the final result.</p>
<p>There are also rules when need to split text that includes, for example, code.</p>
<p>This is the main change between GPT-2 and GPT-4 Tokenizers.</p>
<h2 id="techniques">Techniques</h2>
<h3 id="byte-pair-encoding-bpe">Byte Pair Encoding (BPE)</h3>
<p>It is a technique that wants to compress the output encoding by encoding together the pairs of most common bytes.
It is essentially a token embeddings' algorithm.</p>
<p>For example: [aaabbaabaacaa] &rarr; The sequence "aa" is the most common &rarr; Z = aa &rarr; [ZabbZbZcZ]   </p>
<p>This would reduce the length of the output sequence. This can be done recursively and shortening each time the output sequence. </p>
<p>It is possible to perform a hyperparameter tuning process in order to understand which is the best Vocabulary size that has the
best compression (i.e, the number of times we repeat the Byte Pair Encoding).</p>
<h3 id="special-tokens">Special Tokens</h3>
<p>With the <code>TikToken</code> library it is possible to add special tokens to the Encoder.</p>
<p>For example the <code>&lt;endoftext&gt;</code> and assign it with an unused index.</p>
<h2 id="training">Training</h2>
<h3 id="general">General</h3>
<p>The Tokenizer has its own training set, separated from the LLM's training.</p>
<p>Taking into account the training dataset and the "Diluted Tokens" problem, it becomes clear that, the more words in the Tokenizer
sees in the training dataset that are, for example, in Japanese, the better the Tokenizer would group up these words into 
the same token. In this way, it would represent a Japanese sentence with far less tokens.</p>
<h2 id="libraries_1">Libraries</h2>
<h3 id="sentencepiece">SentencePiece</h3>
<p>Unlike TikToken, SentencePiece is pretty good with both training and inference:</p>
<ul>
<li>TikToken - Encode to UTF-8 and then applied BPE</li>
<li>SentencePiece - Apply BPE directly on the code points (and eventually falls back to UTF-8 for certain code points)</li>
</ul>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../transformers/" class="btn btn-neutral float-left" title="Transformers"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../embeddings/" class="btn btn-neutral float-right" title="Embeddings">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/Volscente/NexusLLM" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../transformers/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../embeddings/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
